{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification_lstm+wordembeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharathichezhiyan/Deep-Learning-with-Keras---Developer-forum-Workshop/blob/master/text_classification_lstm%2Bwordembeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETn03h2nLv1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lqK_LYILv1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNFuy-LmOhdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_words = 5000\n",
        "\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "# call load_data with allow_pickle implicitly set to true\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# restore np.load for future normal usage\n",
        "np.load = np_load_old"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwmZ0OpkLv1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zaR_1n7Lv1b",
        "colab_type": "text"
      },
      "source": [
        "**create** the model architecture we want to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA-cPZlRLv1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    Embedding(top_words, embedding_vecor_length,\n",
        "              input_length=max_review_length)\n",
        "    )\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oIbzY-YLv1e",
        "colab_type": "text"
      },
      "source": [
        "set how to optimize model and compile it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aVn4PIBLv1e",
        "colab_type": "code",
        "outputId": "24bddcc4-b758-4ea4-a7c7-871ae7b686fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvfHdWW8Lv1g",
        "colab_type": "text"
      },
      "source": [
        "train compiled model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaDSnFUmLv1h",
        "colab_type": "code",
        "outputId": "90f35f47-59d7-4e05-fb26-2f0a4cea25a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=64)\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 310s 12ms/step - loss: 0.4765 - acc: 0.7657 - val_loss: 0.3544 - val_acc: 0.8523\n",
            "Accuracy: 85.23%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}